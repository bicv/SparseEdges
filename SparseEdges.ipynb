{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparseEdges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bio-inspired sparse representation of edges in natural images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Table of content\n",
    "\n",
    "* [What is the SparseEdges package?](#What-is-the-SparseEdges-package?) \n",
    "* [Installing](#Installing) \n",
    "* [testing one step](#testing-one-step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the SparseEdges package?\n",
    "================================\n",
    "\n",
    "Our goal here is to build practical algorithms of sparse coding for computer vision.\n",
    "\n",
    "This class exploits the LogGabor package to provide with a sparse representation of edges in images.\n",
    "\n",
    "This algorithm was presented in the following paper:\n",
    "\n",
    "~~~~{.bibtex}\n",
    "@inbook{Perrinet15bicv,\n",
    "    author = {Perrinet, Laurent U.},\n",
    "    booktitle = {Biologically-inspired Computer Vision},\n",
    "    chapter = {13},\n",
    "    citeulike-article-id = {13566753},\n",
    "    editor = {Keil, Matthias and Crist\\'{o}bal, Gabriel and Perrinet, Laurent U.},\n",
    "    keywords = {anr-trax, bicv-sparse},\n",
    "    posted-at = {2015-03-31 14:21:35},\n",
    "    priority = {2},\n",
    "    publisher = {Wiley, New-York},\n",
    "    title = {Sparse models},\n",
    "    year = {2015}\n",
    "}\n",
    "~~~~\n",
    "\n",
    "This package gives a python implementation.\n",
    "\n",
    "Moreover, it gives additional tools to compute useful stistics in images; first- and second order statistics of co-occurences in images.\n",
    "More information is available @ http://nbviewer.ipython.org/github/meduz/SparseEdges/blob/master/SparseEdges.ipynb\n",
    "Tests for the packages are available @ http://nbviewer.ipython.org/github/meduz/SparseEdges/blob/master/test-SparseEdges.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing\n",
    "\n",
    "To install the ``SparseEdges`` class, you would need the ``LogGabor`` class (multiscale filters) which itself depends on the ``SLIP`` class (the image processing tools).\n",
    "\n",
    "    pip install git+https://github.com/meduz/SLIP.git\n",
    "    pip install git+https://github.com/meduz/LogGabor.git \n",
    "    pip install git+https://github.com/meduz/SparseEdges.git\n",
    "    \n",
    "\n",
    "But before, you need th usual depndencies, such as numpy, matplotlib, pyprind and imageio:\n",
    "\n",
    "    pip install -U numpy matplotlib pyprind imageio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#SparseEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)#, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting edges on a sample image\n",
    "\n",
    "We will show here how we can simply reconstruct an example image with the list of extracted edges overlaid.\n",
    "\n",
    "First we define our object by loading default parameters from internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SparseEdges import SparseEdges\n",
    "mp = SparseEdges('https://raw.githubusercontent.com/meduz/SparseEdges/master/default_param.py')\n",
    "print(mp.pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can change these parameters, by instance by using ``2048`` edges and a different value for the $\\alpha$ value in matching pursuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp.pe.N = 2048\n",
    "mp.pe.MP_alpha = .9\n",
    "mp.pe.matpath = 'test/mat'\n",
    "print(mp.pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load an image and make sure to set the framework to the appropriate size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining input image\n",
    "name = 'example'\n",
    "image = mp.imread('https://raw.githubusercontent.com/meduz/SparseEdges/master/database/lena256.png')\n",
    "mp.set_size(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then, we can initialize the algorithm and normalize the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp.init()\n",
    "image = mp.normalize(image, center=True)\n",
    "print(image.mean(), image.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thenit is easy to run matching pursuit on that image (or load a cached file with the results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(os.path.join(mp.pe.matpath, name + '.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    edges = np.load(os.path.join(mp.pe.matpath, name + '.npy'))\n",
    "except:\n",
    "    edges, C_res = mp.run_mp(image, verbose=True)\n",
    "    np.save(matname, edges)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize that in one script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test/experiment_example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test/experiment_example.py\n",
    "#! /usr/bin/env python\n",
    "# -*- coding: utf8 -*-\n",
    "from __future__ import division, print_function\n",
    "\"\"\"\n",
    "\n",
    "An example MP run.\n",
    "\n",
    "To run:\n",
    "$ python test/experiment_example.py \n",
    "\n",
    "To remove cache:\n",
    "$ rm -fr **/example*\n",
    "\n",
    "\"\"\"\n",
    "__author__ = \"(c) Laurent Perrinet INT - CNRS\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from SparseEdges import SparseEdges\n",
    "mp = SparseEdges('https://raw.githubusercontent.com/meduz/SparseEdges/master/default_param.py')\n",
    "mp.N = 128\n",
    "\n",
    "image = mp.imread('https://raw.githubusercontent.com/meduz/SparseEdges/master/database/lena256.png')\n",
    "\n",
    "name = 'example'\n",
    "image = mp.normalize(image, center=True)\n",
    "#print image.mean(), image.std()\n",
    "\n",
    "import os\n",
    "matname = os.path.join(mp.pe.matpath, name + '.npy')\n",
    "try:\n",
    "    edges = np.load(matname)\n",
    "except:\n",
    "    edges, C_res = mp.run_mp(image, verbose=True)\n",
    "    np.save(matname, edges)    \n",
    "\n",
    "matname_RMSE = 'mat/example_RMSE.npy'\n",
    "try:\n",
    "    RMSE = np.load(matname_RMSE)\n",
    "except:\n",
    "    RMSE = np.ones(mp.N)\n",
    "    image_ = image.copy()\n",
    "    image_rec = np.zeros_like(image_)\n",
    "    if mp.do_whitening: image_ = mp.im.whitening(image_)\n",
    "    for i_N in range(mp.N):\n",
    "        image_rec += mp.reconstruct(edges[:, i_N][:, np.newaxis])\n",
    "        RMSE[i_N] =  ((image_*im.mask-image_rec*im.mask)**2).sum()\n",
    "\n",
    "    np.save(matname_RMSE, RMSE)            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lolo/pool/science/BICV-book/SI_BICV_sparse/SparseEdges/test\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'unicode' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Users/lolo/pool/science/BICV-book/SI_BICV_sparse/SparseEdges/test/experiment_example.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# defining input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database/yelmo'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'database/lena'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#print image.mean(), image.std()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lolo/pool/science/BICV-book/SI_BICV_sparse/SLIP/src/SLIP.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(self, URL, resize)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mresize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_X\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_Y\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'unicode' object has no attribute 'shape'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lolo/pool/science/BICV-book/SI_BICV_sparse/SparseEdges\n"
     ]
    }
   ],
   "source": [
    "%cd test\n",
    "%run experiment_example.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the results of the sparse edge extraction with the edges overlaid on the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp.pe.figsize_edges = 12\n",
    "mp.pe.line_width = 3.\n",
    "mp.pe.scale = .5\n",
    "\n",
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(mp.whitening(image)), show_phase=False, mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the dashed circle which (as in Geisler, 2001) shows the limit after which we discard edges. Indeed, when computing statistics (our main goal) we wish to be not perturbed by the fact that images are rectangular.\n",
    "\n",
    "Let's show the results of the sparse edge extraction with the edges overlaid on the image reconstructed from the edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_rec = mp.reconstruct(edges, mask=True)        \n",
    "fig, a = mp.show_edges(edges, image=mp.dewhitening(image_rec), show_phase=False, mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! this test report is about the MatchingPursuit class:\n",
    "print(SparseEdges.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full tutorial on Matching Pursuit, see http://blog.invibe.net/posts/2015-05-22-a-hitchhiker-guide-to-matching-pursuit.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of parameters on edge extraction: image size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile test/experiment_fig-sparselets.py\n",
    "#! /usr/bin/env python\n",
    "# -*- coding: utf8 -*-\n",
    "from __future__ import division, print_function\n",
    "\"\"\"\n",
    "\n",
    "$ python test/experiment_fig-sparselets.py ./figures\n",
    "\n",
    "$ rm -fr **/SparseLets* **/**/SparseLets* \n",
    "\n",
    "\"\"\"\n",
    "__author__ = \"(c) Laurent Perrinet INT - CNRS\"\n",
    "    \n",
    "from SparseEdges import SparseEdges\n",
    "FORMATS = ['pdf', 'eps']\n",
    "mps = []\n",
    "sizes = [16, 32, 64, 128, 256]\n",
    "N_image = 32\n",
    "N = 1024\n",
    "\n",
    "for size, size_str in zip(sizes, ['_016', '_032', '_064',  '_128', '']):\n",
    "    mp = SparseEdges('https://raw.githubusercontent.com/meduz/SparseEdges/master/default_param.py')\n",
    "    mp.pe.seed = 42\n",
    "    mp.pe.datapath = '../../SLIP/database/'\n",
    "    mp.set_size((size, size))\n",
    "    downscale_factor = sizes[-1]/size # > 1\n",
    "    mp.pe.N_image = int(N_image*downscale_factor)\n",
    "    mp.pe.N = int(N/downscale_factor**2)\n",
    "    mp.init()\n",
    "    mp.process('SparseLets' + size_str)\n",
    "    mps.append(mp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig_width_pt = 600 # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "fig = plt.figure(figsize=(fig_width, fig_width/1.618))\n",
    "\n",
    "sizes = [16, 32, 64, 128, 256]\n",
    "experiments = ['SparseLets_' + '%0.3d' % size for size in sizes]\n",
    "experiments[-1] = 'SparseLets'\n",
    "databases = ['serre07_distractors'] * len(experiments)\n",
    "labels = [str(size) for size in sizes]\n",
    "fig, ax, inset = mp.plot(fig=fig, mps=mps, experiments=experiments, databases=databases, \n",
    "                  labels=labels, scale=True)    \n",
    "FORMATS = ['pdf', 'eps']\n",
    "for ext in FORMATS: fig.savefig(mps[0].pe.figpath + 'SparseLets_B.' + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd test\n",
    "%run experiment_fig-sparselets.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of parameters on edge extraction: filter parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile test/experiment_fig-efficiency.py\n",
    "#! /usr/bin/env python\n",
    "# -*- coding: utf8 -*-\n",
    "from __future__ import division, print_function\n",
    "\"\"\"\n",
    "\n",
    "$ ipython experiment_fig-efficiency.py\n",
    "\n",
    "rm -fr **/efficiency_* **/**/efficiency_* \n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from SparseEdges import SparseEdges\n",
    "FORMATS = ['pdf', 'eps']\n",
    "\n",
    "threshold = None # classical plots\n",
    "threshold = .3 # plot L0 sparseness obtained when reaching this threshold\n",
    " \n",
    "mp = SparseEdges('https://raw.githubusercontent.com/meduz/SparseEdges/master/default_param.py')\n",
    "def init_mp():\n",
    "    mp = SparseEdges('https://raw.githubusercontent.com/meduz/SparseEdges/master/default_param.py')\n",
    "    mp.pe.seed = 42\n",
    "    mp.pe.N_image = 60\n",
    "    mp.pe.datapath = '../../SLIP/database/'\n",
    "    return mp\n",
    "\n",
    "    \n",
    "FORMATS = ['pdf', 'eps']\n",
    "#FORMATS = ['png']\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "#matplotlib.rcParams.update({'font.size': 18, 'font.family': 'STIXGeneral', 'mathtext.fontset': 'stix'})\n",
    "matplotlib.rcParams.update({'text.usetex': False})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig_width_pt = 800 #318.67085 # Get this from LaTeX using \\showthe\\columnwidth\n",
    "inches_per_pt = 1.0/72.27               # Convert pt to inches\n",
    "fig_width = fig_width_pt*inches_per_pt  # width in inches\n",
    "\n",
    "# ==================================================================================================#\n",
    "fig, [[A, B], [C, D]] = plt.subplots(2, 2, figsize=(fig_width, fig_width), subplot_kw={'axisbg':'w'})\n",
    "# ==================================================================================================#\n",
    "mps, experiments = [], []\n",
    "v_B_sf = np.logspace(-.2, .2, 5, base=10, endpoint=True)*mp.pe.B_sf\n",
    "for B_sf in v_B_sf:\n",
    "    mp = init_mp()\n",
    "    mp.pe.B_sf = B_sf\n",
    "    exp = 'efficiency_B_sf_' + str(B_sf).replace('.', '_')\n",
    "    mp.process(exp)\n",
    "    experiments.append(exp)\n",
    "    mps.append(mp)\n",
    "\n",
    "databases = ['serre07_distractors'] * len(experiments)\n",
    "labels = ['%0.2f' % B_sf for B_sf in v_B_sf]\n",
    "try:\n",
    "    fig, A, inset = mp.plot(mps=mps,\n",
    "                      experiments=experiments, databases=databases, labels=labels, ref=2,\n",
    "                      fig=fig, ax=A, color=[0., 1., 0.], threshold=threshold, scale=False)    \n",
    "    A.set_xlabel(r'frequency bandwith $B_{sf}$')\n",
    "    #A.set_yticks([0., 0.02, 0.04, 0.06])\n",
    "except Exception as e:\n",
    "    print('Failed to plot  with error : %s ' % e )\n",
    "\n",
    "# ==================================================================================================#    \n",
    "mps, experiments = [], []\n",
    "v_B_theta = np.logspace(-.5, .5, 5, base=10, endpoint=True)*mp.pe.B_theta\n",
    "for B_theta in v_B_theta:\n",
    "    mp = init_mp()\n",
    "    mp.pe.B_theta = B_theta\n",
    "    exp = 'efficiency_B_theta_' + str(B_theta).replace('.', '_')\n",
    "    mp.process(exp)\n",
    "    experiments.append(exp)\n",
    "    mps.append(mp)\n",
    "\n",
    "databases = ['serre07_distractors'] * len(experiments)\n",
    "labels = ['%0.2f' % B_theta for B_theta in v_B_theta]\n",
    "try:\n",
    "    fig, B, inset = mp.plot(mps=mps, \n",
    "                      experiments=experiments, databases=databases, labels=labels, ref=2, \n",
    "                      fig=fig, ax=B, threshold=threshold, scale=False, color=[0., 1., 0.])    \n",
    "    B.set_xlabel(r'orientation bandwith $B_{\\theta}$ (radians)')\n",
    "    B.set_ylabel('')\n",
    "    #B.set_yticks([0., 0.02, 0.04, 0.06])\n",
    "    #B.set_yticklabels(['', '', '', ''])\n",
    "except Exception as e:\n",
    "    print('Failed to plot  with error : %s ' % e )\n",
    "\n",
    "# ==================================================================================================#    \n",
    "mps, experiments = [], []\n",
    "v_n_theta = [6, 12, 24, 48]\n",
    "for n_theta in v_n_theta:\n",
    "    mp = init_mp()\n",
    "    mp.pe.n_theta = n_theta\n",
    "    mp = init_mp()\n",
    "    exp = 'efficiency_n_theta_' + str(n_theta).replace('.', '_')\n",
    "    mp.process(exp)\n",
    "    experiments.append(exp)\n",
    "    mps.append(mp)\n",
    "\n",
    "databases = ['serre07_distractors'] * len(experiments)\n",
    "labels = [str(n_theta) for n_theta in v_n_theta]\n",
    "try:\n",
    "    fig, C, inset = mp.plot(mps=mps, \n",
    "                      experiments=experiments, databases=databases, labels=labels, ref=2, \n",
    "                      fig=fig, ax=C, threshold=threshold, scale=True, color=[0., 1., 0.])    \n",
    "    C.set_xlabel(r'number of orientations $N_{\\theta}$')\n",
    "    #C.set_yticks([0., 0.02, 0.04, 0.06])\n",
    "except Exception as e:\n",
    "    print('Failed to plot  with error : %s ' % e )\n",
    "\n",
    "# ==================================================================================================#    \n",
    "mps, experiments = [], []\n",
    "v_base_levels = [np.sqrt(2), np.sqrt(5)/2.+.5, np.sqrt(3), 2. , np.sqrt(5)]\n",
    "#np.logspace(.25, 1.25, 5, base=2, endpoint=True)\n",
    "for base_levels in v_base_levels:\n",
    "    mp = init_mp()\n",
    "    mp.pe.base_levels = base_levels\n",
    "    mp = init_mp()\n",
    "    exp = 'efficiency_base_levels_' + str(base_levels).replace('.', '_')\n",
    "    mp.process(exp)\n",
    "    experiments.append(exp)\n",
    "    mps.append(mp)\n",
    "\n",
    "databases = ['serre07_distractors'] * len(experiments)\n",
    "labels = ['%0.2f' % (base_levels) for base_levels in v_base_levels]\n",
    "labels[0] = r'$\\sqrt{2}$'\n",
    "labels[1] = r'$\\phi$'\n",
    "labels[3] = '2'\n",
    "try:\n",
    "    fig, D, inset = mp.plot(mps=mps, \n",
    "                      experiments=experiments, databases=databases, labels=labels, ref=3, \n",
    "                      fig=fig, ax=D, threshold=threshold, scale=True, color=[0., 1., 0.])    \n",
    "    D.set_xlabel(r'scale ratio')\n",
    "    D.set_ylabel('')\n",
    "    D.set_yticks([0., 1., 1.3])\n",
    "    D.set_yticklabels(['0', '1', ''])\n",
    "except Exception as e:\n",
    "    print('Failed to plot  with error : %s ' % e )\n",
    "\n",
    "for ax, label in zip([A, B, C, D], ['A', 'B', 'C', 'D']):\n",
    "    ax.text(-.1, .95, label, transform=ax.transAxes, fontsize=12) #'('+label+')'\n",
    "    ax.set_ylim([0., 1.6])\n",
    "    ax.set_yticks([0., 1., 1.4])\n",
    "    ax.set_yticklabels([\"0\", '1', ''])\n",
    "    if label in ['B', 'D']: ax.set_yticklabels(['', '', ''])\n",
    "\n",
    "\n",
    "# TODO : show CRF\n",
    "        \n",
    "#The parameter meanings (and suggested defaults) are::\n",
    "#\n",
    "#  left  = 0.125  # the left side of the subplots of the figure\n",
    "#  right = 0.9    # the right side of the subplots of the figure\n",
    "#  bottom = 0.1   # the bottom of the subplots of the figure\n",
    "#  top = 0.9      # the top of the subplots of the figure\n",
    "#  wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "#  hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "fig.subplots_adjust(wspace=0.12, hspace=0.3,\n",
    "                            left=0.125, right=0.98,\n",
    "                            top=0.98,    bottom=0.12)\n",
    "    \n",
    "for ext in FORMATS: fig.savefig(mp.pe.figpath + 'efficiency.' + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd test\n",
    "%run experiment_fig-efficiency.py\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we test different parameters for the filters, we measured the gain in efficiency for the algorithm as the ratio of the code length to achieve $85\\%$ of energy extraction relative to that for the default parameters (white bar). The average is computed on the same database of natural images and error bars denote the standard deviation of gain over the database. First, we studied the effect of the bandwidth of filters respectively in the $\\textsf{(A)}$ spatial frequency and $\\textsf{(B)}$ orientation spaces. The minimum is reached for the default parameters: this shows that default parameters provide an optimal compromise between the precision of filters in the frequency and position domains for this database. We may also compare pyramids with different number of filters.  Indeed, efficiency (in bits) is equal to the number of selected filters times the coding cost for the address of each edge in the pyramid.\n",
    "We plot here the average gain in efficiency which shows an optimal compromise respectively for respectively $\\textsf{(C)}$ the number of orientations and $\\textsf{(D)}$ the number of spatial frequencies (scales). Note first that with more than 12 directions, the gain remains stable. Note also that a dyadic scale ratio (that is of 2) is efficient but that other solutions ---such as using the golden section $\\phi$--- prove to be significantly more efficient, though the average gain is relatively small (inferior to $5\\%$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some book keeping for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.githubusercontent.com/rasbt/python_reference/master/ipython_magic/watermark.py\n",
    "%load_ext watermark\n",
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%install_ext http://raw.github.com/jrjohansson/version_information/master/version_information.py\n",
    "%load_ext version_information\n",
    "%version_information numpy, scipy, matplotlib, sympy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
